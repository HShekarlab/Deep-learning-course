{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yG_n40gFzf9s"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pD_55cOxLkAb"
   },
   "outputs": [],
   "source": [
    "path_to_file = \"shahnameh.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aavnuByVymwK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 2653849 characters\n"
     ]
    }
   ],
   "source": [
    "text = open(path_to_file, \"rb\").read().decode(encoding= \"utf-8\")\n",
    "print (\"Length of text: {} characters\".format(len(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Duhg9NrUymwO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|به نام خداوند جان و خرد\n",
      "|کزین برتر اندیشه برنگذرد\n",
      "|خداوند نام و خداوند جای\n",
      "|خداوند روزی ده رهنمای\n",
      "|خداوند کیوان و گردان سپهر\n",
      "|فروزنده ماه و ناهید و مهر\n",
      "|ز نام و نشان و گمان برترست\n",
      "|نگارندهٔ بر شده پیکرست\n",
      "|به بینندگان آفریننده را\n",
      "|نبینی مرنجان دو بین\n"
     ]
    }
   ],
   "source": [
    "print(text[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IlCgQBRVymwR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 unique characters\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(text))\n",
    "print (\"{} unique characters\".format(len(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IalZLbvOzf-F"
   },
   "outputs": [],
   "source": [
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FYyNlCNXymwY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  '\\n':   0,\n",
      "  ' ' :   1,\n",
      "  '(' :   2,\n",
      "  ')' :   3,\n",
      "  '|' :   4,\n",
      "  '«' :   5,\n",
      "  '»' :   6,\n",
      "  '،' :   7,\n",
      "  '؟' :   8,\n",
      "  'ء' :   9,\n",
      "  'آ' :  10,\n",
      "  'أ' :  11,\n",
      "  'ؤ' :  12,\n",
      "  'ئ' :  13,\n",
      "  'ا' :  14,\n",
      "  'ب' :  15,\n",
      "  'ت' :  16,\n",
      "  'ث' :  17,\n",
      "  'ج' :  18,\n",
      "  'ح' :  19,\n",
      "  ...\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"{\")\n",
    "for char,_ in zip(char2idx, range(20)):\n",
    "    print(\"  {:4s}: {:3d},\".format(repr(char), char2idx[char]))\n",
    "print(\"  ...\\n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l1VKcQHcymwb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'|به نام خداون' ---- characters mapped to int ---- > [ 4 15 38  1 37 14 36  1 20 21 14 39 37]\n"
     ]
    }
   ],
   "source": [
    "print (\"{} ---- characters mapped to int ---- > {}\".format(repr(text[:13]), text_as_int[:13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0UHJDA39zf-O"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|\n",
      "ب\n",
      "ه\n",
      " \n",
      "ن\n"
     ]
    }
   ],
   "source": [
    "seq_length = 100\n",
    "\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "for i in char_dataset.take(5):\n",
    "  print(idx2char[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l4hkDU3i7ozi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'|به نام خداوند جان و خرد\\n|کزین برتر اندیشه برنگذرد\\n|خداوند نام و خداوند جای\\n|خداوند روزی ده رهنمای\\n|خ'\n",
      "***************\n",
      "'داوند کیوان و گردان سپهر\\n|فروزنده ماه و ناهید و مهر\\n|ز نام و نشان و گمان برترست\\n|نگارندهٔ بر شده پیکر'\n",
      "***************\n",
      "'ست\\n|به بینندگان آفریننده را\\n|نبینی مرنجان دو بیننده را\\n|نیابد بدو نیز اندیشه راه\\n|که او برتر از نام و'\n",
      "***************\n",
      "' از جایگاه\\n|سخن هر چه زین گوهران بگذرد\\n|نیابد بدو راه جان و خرد\\n|خرد گر سخن برگزیند همی\\n|همان را گزین'\n",
      "***************\n",
      "'د که بیند همی\\n|ستودن نداند کس او را چو هست\\n|میان بندگی را ببایدت بست\\n|خرد را و جان را همی سنجد اوی\\n|د'\n",
      "***************\n"
     ]
    }
   ],
   "source": [
    "sequences = char_dataset.batch(seq_length + 1, drop_remainder=True)\n",
    "\n",
    "for item in sequences.take(5):\n",
    "    print(repr(\"\".join(idx2char[item.numpy()])))\n",
    "    print(\"***\" * 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9NGu-FkO_kYU"
   },
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GNbw-iR0ymwj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  '|به نام خداوند جان و خرد\\n|کزین برتر اندیشه برنگذرد\\n|خداوند نام و خداوند جای\\n|خداوند روزی ده رهنمای\\n|'\n",
      "Target data: 'به نام خداوند جان و خرد\\n|کزین برتر اندیشه برنگذرد\\n|خداوند نام و خداوند جای\\n|خداوند روزی ده رهنمای\\n|خ'\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in  dataset.take(1):\n",
    "  print (\"Input data: \", repr(\"\".join(idx2char[input_example.numpy()])))\n",
    "  print (\"Target data:\", repr(\"\".join(idx2char[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0eBu9WZG84i0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step    0\n",
      "  input: 4 ('|')\n",
      "  expected output: 15 ('ب')\n",
      "Step    1\n",
      "  input: 15 ('ب')\n",
      "  expected output: 38 ('ه')\n",
      "Step    2\n",
      "  input: 38 ('ه')\n",
      "  expected output: 1 (' ')\n",
      "Step    3\n",
      "  input: 1 (' ')\n",
      "  expected output: 37 ('ن')\n",
      "Step    4\n",
      "  input: 37 ('ن')\n",
      "  expected output: 14 ('ا')\n"
     ]
    }
   ],
   "source": [
    "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
    "    print(\"Step {:4d}\".format(i))\n",
    "    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
    "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p2pGotuNzf-S"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zHT8cLh7EAsg"
   },
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_dim = 25\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MtCrdfzEI2N0"
   },
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "  model = tf.keras.Sequential([\n",
    "          tf.keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[batch_size, None]),\n",
    "          tf.keras.layers.GRU(rnn_units, return_sequences=True, stateful=True, recurrent_initializer = \"glorot_uniform\"),\n",
    "          tf.keras.layers.Dense(vocab_size)])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wwsrpOik5zhv"
   },
   "outputs": [],
   "source": [
    "model = build_model(vocab_size = len(vocab),\n",
    "                    embedding_dim = embedding_dim,\n",
    "                    rnn_units = rnn_units,\n",
    "                    batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C-_70kKAPrPU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 48) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "  example_batch_predictions = model.predict(input_example_batch)\n",
    "  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vPGmAAXmVLGC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (64, None, 25)            1200      \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (64, None, 1024)          3228672   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, None, 48)            49200     \n",
      "=================================================================\n",
      "Total params: 3,279,072\n",
      "Trainable params: 3,279,072\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4V4MfFg0RQJg"
   },
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples = 1)\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis = -1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YqFMUQc_UFgM"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([38, 47, 10, 11, 21, 29, 37, 41, 13, 35, 41, 23, 12, 21, 41, 15, 47,\n",
       "       29,  3, 10, 42, 33, 12, 13, 18,  4, 35, 27, 41, 16,  8, 45, 15, 43,\n",
       "        8, 40, 28, 35, 29,  3,  5,  8, 17, 32, 10, 44, 25, 24, 45, 24, 26,\n",
       "       40, 19,  8,  6, 45, 25,  3, 31, 13, 28, 12,  6, 46, 22, 45, 12, 33,\n",
       "       42, 33,  0, 15, 32, 36, 45, 22, 33, 44, 43, 33, 36, 36,  9, 47,  4,\n",
       "       18,  0, 31, 33, 33,  0, 45, 37, 15, 44, 22, 30, 10, 29, 28],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xWcFwPwLSo05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      " '|به نام خداوند جان و خرد\\n|کزین برتر اندیشه برنگذرد\\n|خداوند نام و خداوند جای\\n|خداوند روزی ده رهنمای\\n|'\n",
      "\n",
      "Next Char Predictions: \n",
      " 'ه\\u200cآأدطنپئلپرؤدپب\\u200cط)آچفؤئج|لصپت؟گبژ؟ٔضلط)«؟ثغآکسزگزشٔح؟»گس)عئضؤ»یذگؤفچف\\nبغمگذفکژفممء\\u200c|ج\\nعفف\\nگنبکذظآطض'\n"
     ]
    }
   ],
   "source": [
    "print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
    "print()\n",
    "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices ])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4HrXTACTdzY-"
   },
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DDl1_Een6rL0"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = \"adam\", loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W6fWTriUZP-n"
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = \"./training_checkpoints\"\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix, save_weights_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7yGBE2zxMMHs"
   },
   "outputs": [],
   "source": [
    "Epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UK-hmKjYVoll"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "410/410 [==============================] - 129s 314ms/step - loss: 2.4480\n",
      "Epoch 2/10\n",
      "410/410 [==============================] - 149s 363ms/step - loss: 1.8074\n",
      "Epoch 3/10\n",
      "410/410 [==============================] - 152s 371ms/step - loss: 1.5528\n",
      "Epoch 4/10\n",
      "410/410 [==============================] - 154s 375ms/step - loss: 1.4235\n",
      "Epoch 5/10\n",
      "410/410 [==============================] - 154s 377ms/step - loss: 1.3444\n",
      "Epoch 6/10\n",
      "410/410 [==============================] - 157s 382ms/step - loss: 1.2861\n",
      "Epoch 7/10\n",
      "410/410 [==============================] - 157s 383ms/step - loss: 1.2370\n",
      "Epoch 8/10\n",
      "410/410 [==============================] - 136s 331ms/step - loss: 1.1920\n",
      "Epoch 9/10\n",
      "410/410 [==============================] - 147s 359ms/step - loss: 1.1487\n",
      "Epoch 10/10\n",
      "410/410 [==============================] - 152s 370ms/step - loss: 1.1066\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs = Epoch, callbacks = [checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zk2WJ2-XjkGz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./training_checkpoints\\\\ckpt_10'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LycQ-ot_jjyu"
   },
   "outputs": [],
   "source": [
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size = 1)\n",
    "\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "71xa6jnYVrAN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (1, None, 25)             1200      \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (1, None, 1024)           3228672   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (1, None, 48)             49200     \n",
      "=================================================================\n",
      "Total params: 3,279,072\n",
      "Trainable params: 3,279,072\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WvuwZBX5Ogfd"
   },
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "  num_generate = 1000\n",
    "  input_eval = [char2idx[s] for s in start_string]\n",
    "  input_eval = tf.expand_dims(input_eval, 0)\n",
    "  text_generated = []\n",
    "\n",
    "  model.reset_states()\n",
    "  for i in range(num_generate):\n",
    "      predictions = model(input_eval)\n",
    "      predictions = tf.squeeze(predictions, 0)\n",
    "      predictions = predictions \n",
    "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
    "      input_eval = tf.expand_dims([predicted_id], 0)\n",
    "      text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "  return (start_string + \"\".join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ktovv0RFhrkn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "به نام خدایست نستوه تو\n",
      "|به گیتی نماید نگارد ز بتاختی\n",
      "|وزان پس چنین تا برآرم بماه\n",
      "|صد آن تختها برکشمد از تو بر تن خویش یابی به خون\n",
      "|ز شادی شگفتی که بیکار گشت\n",
      "|دوماه\n",
      "|کجا آن همه ریز کردم همی\n",
      "|ز تخم بد و باژ و پر بوی مهر\n",
      "|شنیده تخت باژی چو کوه بزرگ\n",
      "|بدست سخن گوی برخاستند\n",
      "|به زندان بیاوردش از جنگ جفت\n",
      "|یکی دیگر آنگه که تن بگذرد\n",
      "|من آن تخت راخسر بر تنگ هنگام موسن شود\n",
      "|سربخت این را که پوشیده‌ام\n",
      "|سراسان کنم داد و دانندگان\n",
      "|گلاب و عنان برگرفتند راه\n",
      "|نماند به رستم که لشکر براند\n",
      "|چه افگند دینار و گرمان به دست\n",
      "|چو ارجات داری خرامید یاد\n",
      "|که نزد کزت بر تو بر خاک روی\n",
      "|شهنشاه بینندهٔ رخش بروخون\n",
      "|تو گفتی همی درکشید این سخن\n",
      "|سواری بر اب گوهرنگار\n",
      "|صزو تن به پا اندر آویختست\n",
      "|نه زین باره و گردیه را بدست\n",
      "|به خون خسره آیید گفتار من\n",
      "|نگردد به بازد اسیدش تخل به درد\n",
      "|سوی حلبهاد آن سه زر\n",
      "|سپاس از دبیرو ستم\n",
      "|همی دشمنندان او تخت را نو نمرد\n",
      "|هرآنکس که او دشمن ایمن ببین\n",
      "|بدو گفت بهرام چون بر روان\n",
      "|یبا پیرسر گفت زن پر ز خون\n",
      "|نگه کرده و از بلت خسرو شوردار\n",
      "|بدآنید تاوان به ایران تویی\n",
      "|\n",
      "|ار و دوبست و زه برکشد\n",
      "|فروشد نه بیما نیر خ\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string = u\"به نام خدا\"))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "text_generation.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
